{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cattle Breed Classification Training\n",
    "\n",
    "## EfficientNet-B0 Training on Google Colab (Free T4 GPU)\n",
    "\n",
    "This notebook trains the breed classification model using EfficientNet-B0.\n",
    "\n",
    "**Target:** 85%+ accuracy on Indian cattle and buffalo breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "\n",
    "# If GPU not available, go to Runtime > Change runtime type > GPU\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"GPU Device:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q tensorflow==2.12.0\n",
    "!pip install -q keras==2.12.0\n",
    "!pip install -q opencv-python\n",
    "!pip install -q matplotlib seaborn\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for data storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths\n",
    "import os\n",
    "BASE_DIR = '/content/drive/MyDrive/cattle-breed-recognition'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indian cattle and buffalo breeds\n",
    "CATTLE_BREEDS = [\n",
    "    \"Gir\", \"Sahiwal\", \"Red Sindhi\", \"Tharparkar\", \"Rathi\",\n",
    "    \"Hallikar\", \"Amritmahal\", \"Khillari\", \"Kangayam\", \"Bargur\",\n",
    "    \"Hariana\", \"Kankrej\", \"Ongole\", \"Deoni\", \"Krishna Valley\",\n",
    "    \"Punganur\", \"Vechur\", \"Malnad Gidda\",\n",
    "    \"Jersey Cross\", \"HF Cross\"\n",
    "]\n",
    "\n",
    "BUFFALO_BREEDS = [\n",
    "    \"Murrah\", \"Jaffrabadi\", \"Nili-Ravi\", \"Banni\",\n",
    "    \"Pandharpuri\", \"Mehsana\", \"Surti\", \"Nagpuri\",\n",
    "    \"Toda\", \"Bhadawari\"\n",
    "]\n",
    "\n",
    "ALL_BREEDS = CATTLE_BREEDS + BUFFALO_BREEDS\n",
    "NUM_CLASSES = len(ALL_BREEDS)\n",
    "\n",
    "print(f\"Total breeds: {NUM_CLASSES}\")\n",
    "print(f\"Cattle breeds: {len(CATTLE_BREEDS)}\")\n",
    "print(f\"Buffalo breeds: {len(BUFFALO_BREEDS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create breed to index mapping\n",
    "BREED_TO_IDX = {breed: idx for idx, breed in enumerate(ALL_BREEDS)}\n",
    "IDX_TO_BREED = {idx: breed for breed, idx in BREED_TO_IDX.items()}\n",
    "\n",
    "# Save mappings\n",
    "import json\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, 'breed_mapping.json'), 'w') as f:\n",
    "    json.dump({'breed_to_idx': BREED_TO_IDX, 'idx_to_breed': {str(k): v for k, v in IDX_TO_BREED.items()}}, f)\n",
    "\n",
    "print(\"Breed mapping saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Image size for EfficientNet-B0\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation and test data generator (no augmentation)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "print(\"Data generators created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from directory structure\n",
    "# Expected structure:\n",
    "# data/\n",
    "#   train/\n",
    "#     Gir/\n",
    "#     Sahiwal/\n",
    "#     ...\n",
    "#   val/\n",
    "#     ...\n",
    "#   test/\n",
    "#     ...\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# Check if data exists\n",
    "if os.path.exists(TRAIN_DIR):\n",
    "    print(\"Loading data from directories...\")\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_generator = val_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "    print(f\"Validation samples: {val_generator.samples}\")\n",
    "    print(f\"Test samples: {test_generator.samples}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Data directory not found. Please upload your dataset to Google Drive.\")\n",
    "    print(f\"Expected path: {TRAIN_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "def build_model(num_classes, input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Build EfficientNet-B0 based classifier.\n",
    "    \"\"\"\n",
    "    # Load pretrained backbone\n",
    "    backbone = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze backbone initially\n",
    "    for layer in backbone.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build classification head\n",
    "    x = backbone.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(backbone.input, outputs, name='efficientnet_breed_classifier')\n",
    "    \n",
    "    return model, backbone\n",
    "\n",
    "# Build model\n",
    "model, backbone = build_model(NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)]\n",
    ")\n",
    "\n",
    "print(\"Model compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, \n",
    "    ReduceLROnPlateau, \n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")\n",
    "\n",
    "checkpoint_path = os.path.join(MODEL_DIR, 'checkpoints')\n",
    "log_path = os.path.join(MODEL_DIR, 'logs')\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=7,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(checkpoint_path, 'best_model.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(log_dir=log_path)\n",
    "]\n",
    "\n",
    "print(\"Callbacks ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Train classification head\n",
    "EPOCHS_PHASE1 = 10\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Phase 1: Training classification head (frozen backbone)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS_PHASE1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Fine-tune last layers\n",
    "EPOCHS_PHASE2 = 10\n",
    "FINE_TUNE_LAYERS = 20\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Phase 2: Fine-tuning last {FINE_TUNE_LAYERS} layers\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Unfreeze last N layers\n",
    "for layer in backbone.layers[-FINE_TUNE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS_PHASE1 + EPOCHS_PHASE2,\n",
    "    initial_epoch=EPOCHS_PHASE1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history, title=''):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label='Train')\n",
    "    axes[0].plot(history.history['val_loss'], label='Val')\n",
    "    axes[0].set_title(f'{title} - Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history.history['accuracy'], label='Train')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Val')\n",
    "    axes[1].set_title(f'{title} - Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot combined history\n",
    "plot_history(history_phase2, 'EfficientNet-B0 Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {test_results[0]:.4f}\")\n",
    "print(f\"  Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"  Top-3 Accuracy: {test_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and confusion matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get class names\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'confusion_matrix.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open(os.path.join(MODEL_DIR, 'classification_report.txt'), 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full model\n",
    "model.save(os.path.join(MODEL_DIR, 'efficientnet_breed_classifier.h5'))\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply quantization for smaller size\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save TFLite model\n",
    "tflite_path = os.path.join(MODEL_DIR, 'breed_classifier.tflite')\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_path}\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"TFLite Model Details:\")\n",
    "print(f\"Input shape: {input_details[0]['shape']}\")\n",
    "print(f\"Output shape: {output_details[0]['shape']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_breed(image_path, model, class_names):\n",
    "    \"\"\"\n",
    "    Predict breed from image.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(img_array)[0]\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_3_idx = np.argsort(predictions)[::-1][:3]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_3_idx:\n",
    "        results.append({\n",
    "            'breed': class_names[idx],\n",
    "            'confidence': float(predictions[idx])\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with sample image (replace with your image path)\n",
    "# sample_image = '/content/drive/MyDrive/sample_cow.jpg'\n",
    "# results = predict_breed(sample_image, model, class_names)\n",
    "# print(\"Top 3 Predictions:\")\n",
    "# for r in results:\n",
    "#     print(f\"  {r['breed']}: {r['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: EfficientNet-B0\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"\\nTest Accuracy: {test_results[1]:.2%}\")\n",
    "print(f\"Test Top-3 Accuracy: {test_results[2]:.2%}\")\n",
    "print(f\"\\nModel saved to: {MODEL_DIR}\")\n",
    "print(f\"TFLite model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
