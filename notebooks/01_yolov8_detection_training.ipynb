{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivam499-pro/Cattle-breed-recognitions/blob/main/notebooks/01_yolov8_detection_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maDaEM8Y4Xao"
      },
      "source": [
        "# YOLOv8-Nano Detection Model Training\n",
        "## Cattle Breed Recognition System - Stage 1: Animal Detection\n",
        "\n",
        "This notebook trains a YOLOv8-Nano model for detecting cattle and buffaloes in images.\n",
        "\n",
        "**Model Specifications:**\n",
        "- Model: YOLOv8-Nano (smallest, fastest)\n",
        "- Input Size: 416x416\n",
        "- Output: Bounding box (x, y, w, h) for animal detection\n",
        "- Final Size: ~5 MB (after INT8 quantization)\n",
        "- Inference: ~20ms on mobile\n",
        "\n",
        "**Author:** SIH 2025 Team\n",
        "**Problem Statement:** SIH25004 - Image-based Breed Recognition for Cattle and Buffaloes of India"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX: PyTorch 2.6+ compatibility (RUN THIS FIRST!)\n",
        "import torch\n",
        "import functools\n",
        "\n",
        "_original_torch_load = torch.load\n",
        "\n",
        "@functools.wraps(_original_torch_load)\n",
        "def _patched_load(f, map_location=None, pickle_module=None, *, weights_only=None, mmap=None, **kwargs):\n",
        "    return _original_torch_load(f, map_location=map_location, pickle_module=pickle_module,\n",
        "                                 weights_only=False, mmap=mmap, **kwargs)\n",
        "\n",
        "torch.load = _patched_load\n",
        "print(\"‚úÖ PyTorch patch applied! Now run the rest of the notebook.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm9Qyv5e5Pki",
        "outputId": "0220ec4b-bddb-4b56-fd36-b5a01a14ecaa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PyTorch patch applied! Now run the rest of the notebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Install YOLOv8\n",
        "!pip install ultralytics==8.0.196 -q\n",
        "!pip install roboflow -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSNfBBKI6ED8",
        "outputId": "eafbd6b4-d154-4990-c6be-6a7eab377a81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive for data storage\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set paths\n",
        "BASE_PATH = '/content/drive/MyDrive/cattle_breed_recognition'\n",
        "...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asSASMFc6q5f",
        "outputId": "0d7a44c3-ef7e-48eb-c4a1-1a8058df7d21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ZIP files from Google Drive backup\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "backup_folder = '/content/drive/MyDrive/cattle_breed_recognition/dataset_backup'\n",
        "print(\"üìÇ Loading ZIP files from Google Drive backup...\")\n",
        "\n",
        "if os.path.exists(backup_folder):\n",
        "    for f in os.listdir(backup_folder):\n",
        "        if f.endswith('.zip'):\n",
        "            src = os.path.join(backup_folder, f)\n",
        "            dst = f'/content/{f}'\n",
        "            if not os.path.exists(dst):\n",
        "                size_mb = os.path.getsize(src) / (1024 * 1024)\n",
        "                print(f\"   Loading: {f} ({size_mb:.1f} MB)\")\n",
        "                shutil.copy2(src, dst)\n",
        "            else:\n",
        "                print(f\"   Already exists: {f}\")\n",
        "    print(\"‚úÖ ZIP files loaded!\")\n",
        "else:\n",
        "    print(\"‚ùå Backup folder not found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PSYFik77lB5",
        "outputId": "8b760e70-1165-46c9-850a-53179fc53ebc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Loading ZIP files from Google Drive backup...\n",
            "‚ùå Backup folder not found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Google Drive contents\n",
        "import os\n",
        "\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "print(\"üìÅ Google Drive contents:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if os.path.exists(drive_path):\n",
        "    for item in sorted(os.listdir(drive_path)):\n",
        "        item_path = os.path.join(drive_path, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   üìÇ {item}/\")\n",
        "        else:\n",
        "            size_mb = os.path.getsize(item_path) / (1024 * 1024)\n",
        "            print(f\"   üìÑ {item} ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"   (empty or not accessible)\")\n",
        "\n",
        "# Check if cattle_breed_recognition folder exists\n",
        "cattle_path = '/content/drive/MyDrive/cattle_breed_recognition'\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "if os.path.exists(cattle_path):\n",
        "    print(f\"‚úÖ cattle_breed_recognition folder exists\")\n",
        "    print(\"Contents:\")\n",
        "    for item in sorted(os.listdir(cattle_path)):\n",
        "        print(f\"   üìÇ {item}/\")\n",
        "else:\n",
        "    print(\"‚ùå cattle_breed_recognition folder not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmfSPsZ98B2K",
        "outputId": "c90c0557-5947-4adb-b75e-1c7ac1bb5eec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Google Drive contents:\n",
            "============================================================\n",
            "   üìÇ Classroom/\n",
            "   üìÇ Colab Notebooks/\n",
            "   üìÑ SHIVAM JAISWAL.png (0.3 MB)\n",
            "   üìÑ Screenshot_20260105_210835.jpg (0.2 MB)\n",
            "   üìÇ cattle_breed_recognition/\n",
            "\n",
            "============================================================\n",
            "‚úÖ cattle_breed_recognition folder exists\n",
            "Contents:\n",
            "   üìÇ 01_yolov8_detection_training.ipynb/\n",
            "   üìÇ 02_efficientnet_classification_training.ipynb/\n",
            "   üìÇ 03_classification_training.ipynb/\n",
            "   üìÇ data/\n",
            "   üìÇ models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE TO GOOGLE DRIVE IMMEDIATELY\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create backup folder\n",
        "backup_folder = '/content/drive/MyDrive/cattle_breed_recognition/dataset_backup'\n",
        "os.makedirs(backup_folder, exist_ok=True)\n",
        "\n",
        "print(\"üíæ Saving ZIP files to Google Drive...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find ZIP files in /content/\n",
        "zip_files = [f for f in os.listdir('/content/') if f.endswith('.zip')]\n",
        "\n",
        "if zip_files:\n",
        "    for zip_name in zip_files:\n",
        "        src = f'/content/{zip_name}'\n",
        "        dst = f'{backup_folder}/{zip_name}'\n",
        "        size_mb = os.path.getsize(src) / (1024 * 1024)\n",
        "        print(f\"   Saving: {zip_name} ({size_mb:.1f} MB)\")\n",
        "        shutil.copy2(src, dst)\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úÖ All ZIP files saved to Google Drive!\")\n",
        "    print(f\"üìÇ Location: {backup_folder}\")\n",
        "else:\n",
        "    print(\"‚ùå No ZIP files found!\")\n"
      ],
      "metadata": {
        "id": "6m87l70bAgWz",
        "outputId": "fce29074-1606-44fa-ec0a-555239913958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving ZIP files to Google Drive...\n",
            "============================================================\n",
            "   Saving: cow breed-3.zip (0.5 MB)\n",
            "   Saving: cow breed-2.zip (0.2 MB)\n",
            "   Saving: cow breed-1.zip (603.5 MB)\n",
            "============================================================\n",
            "‚úÖ All ZIP files saved to Google Drive!\n",
            "üìÇ Location: /content/drive/MyDrive/cattle_breed_recognition/dataset_backup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative: Use unzip command for extraction\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"üì¶ Extracting ZIP files using unzip command...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create temp directory\n",
        "os.makedirs('/content/temp_images', exist_ok=True)\n",
        "\n",
        "zip_files = ['/content/cow breed-1.zip', '/content/cow breed-2.zip', '/content/cow breed-3.zip']\n",
        "\n",
        "for zip_path in zip_files:\n",
        "    if os.path.exists(zip_path):\n",
        "        size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "        print(f\"\\nExtracting: {os.path.basename(zip_path)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        try:\n",
        "            # Use unzip command\n",
        "            result = subprocess.run(\n",
        "                ['unzip', '-o', '-q', zip_path, '-d', '/content/temp_images'],\n",
        "                capture_output=True,\n",
        "                text=True\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"   ‚úÖ Extracted successfully\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è Warning: {result.stderr[:100]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "# Count extracted images\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä Counting extracted images...\")\n",
        "\n",
        "import glob\n",
        "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.JPG', '*.JPEG', '*.PNG']\n",
        "all_images = []\n",
        "\n",
        "for ext in image_extensions:\n",
        "    all_images.extend(glob.glob(f'/content/temp_images/**/{ext}', recursive=True))\n",
        "\n",
        "print(f\"‚úÖ Found {len(all_images)} images\")\n"
      ],
      "metadata": {
        "id": "ckTxlU4RDCQg",
        "outputId": "b4d86ad5-54ad-4ba8-cb5b-d935296ed0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Extracting ZIP files using unzip command...\n",
            "============================================================\n",
            "\n",
            "Extracting: cow breed-1.zip (603.5 MB)\n",
            "   ‚ö†Ô∏è Warning: error [/content/cow breed-1.zip]:  missing 24117248 bytes in zipfile\n",
            "  (attempting to process anyway\n",
            "\n",
            "Extracting: cow breed-2.zip (0.2 MB)\n",
            "   ‚úÖ Extracted successfully\n",
            "\n",
            "Extracting: cow breed-3.zip (0.5 MB)\n",
            "   ‚úÖ Extracted successfully\n",
            "\n",
            "============================================================\n",
            "üìä Counting extracted images...\n",
            "‚úÖ Found 34 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "zip_path = '/content/cow breed-1.zip'\n",
        "if os.path.exists(zip_path):\n",
        "    size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "    print(f\"üì¶ cow breed-1.zip: {size_mb:.1f} MB\")\n",
        "\n",
        "    if size_mb > 620:\n",
        "        print(\"‚úÖ File size looks correct!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è File may still be incomplete. Expected ~626 MB\")\n",
        "else:\n",
        "    print(\"‚ùå File not found\")\n"
      ],
      "metadata": {
        "id": "O9KtLlldEeSs",
        "outputId": "3d8dc667-5dc0-4059-c8ca-5ac5334b76f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ cow breed-1.zip: 626.5 MB\n",
            "‚úÖ File size looks correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the complete ZIP file to Google Drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "backup_folder = '/content/drive/MyDrive/cattle_breed_recognition/dataset_backup'\n",
        "os.makedirs(backup_folder, exist_ok=True)\n",
        "\n",
        "print(\"üíæ Saving complete ZIP file to Google Drive...\")\n",
        "\n",
        "src = '/content/cow breed-1.zip'\n",
        "dst = f'{backup_folder}/cow breed-1.zip'\n",
        "size_mb = os.path.getsize(src) / (1024 * 1024)\n",
        "print(f\"   Saving: cow breed-1.zip ({size_mb:.1f} MB)\")\n",
        "shutil.copy2(src, dst)\n",
        "\n",
        "print(\"‚úÖ Saved to Google Drive!\")\n"
      ],
      "metadata": {
        "id": "nG23yqnaKWdP",
        "outputId": "d53c3c98-b79f-4a50-f75d-01daecceed30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving complete ZIP file to Google Drive...\n",
            "   Saving: cow breed-1.zip (626.5 MB)\n",
            "‚úÖ Saved to Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all ZIP files and create dataset\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "DATASET_PATH = '/content/detection_dataset'\n",
        "\n",
        "# Clean up previous extraction\n",
        "if os.path.exists('/content/temp_images'):\n",
        "    shutil.rmtree('/content/temp_images')\n",
        "os.makedirs('/content/temp_images', exist_ok=True)\n",
        "\n",
        "# Create dataset directories\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    os.makedirs(f'{DATASET_PATH}/{split}/images', exist_ok=True)\n",
        "    os.makedirs(f'{DATASET_PATH}/{split}/labels', exist_ok=True)\n",
        "\n",
        "print(\"üì¶ Extracting all ZIP files...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "zip_files = ['/content/cow breed-1.zip', '/content/cow breed-2.zip', '/content/cow breed-3.zip']\n",
        "\n",
        "for zip_path in zip_files:\n",
        "    if os.path.exists(zip_path):\n",
        "        size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "        print(f\"   Extracting: {os.path.basename(zip_path)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        result = subprocess.run(\n",
        "            ['unzip', '-o', '-q', zip_path, '-d', '/content/temp_images'],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"      ‚úÖ Done\")\n",
        "        else:\n",
        "            print(f\"      ‚ö†Ô∏è {result.stderr[:50] if result.stderr else 'OK'}\")\n",
        "\n",
        "# Count images\n",
        "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.JPG', '*.JPEG', '*.PNG']\n",
        "all_images = []\n",
        "for ext in image_extensions:\n",
        "    all_images.extend(glob.glob(f'/content/temp_images/**/{ext}', recursive=True))\n",
        "\n",
        "print(f\"\\n‚úÖ Found {len(all_images)} images\")\n",
        "\n",
        "# Split and copy\n",
        "if len(all_images) > 0:\n",
        "    random.shuffle(all_images)\n",
        "    n = len(all_images)\n",
        "    train_images = all_images[:int(n*0.7)]\n",
        "    val_images = all_images[int(n*0.7):int(n*0.85)]\n",
        "    test_images = all_images[int(n*0.85):]\n",
        "\n",
        "    def copy_images(images, split):\n",
        "        print(f\"   Copying {len(images)} to {split}...\")\n",
        "        for i, img_path in enumerate(images):\n",
        "            ext = os.path.splitext(img_path)[1]\n",
        "            dest = f'{DATASET_PATH}/{split}/images/image_{i}{ext}'\n",
        "            shutil.copy(img_path, dest)\n",
        "\n",
        "            label_dest = f'{DATASET_PATH}/{split}/labels/image_{i}.txt'\n",
        "            with open(label_dest, 'w') as f:\n",
        "                f.write('0 0.5 0.5 0.8 0.8\\n')\n",
        "\n",
        "            if (i + 1) % 500 == 0:\n",
        "                print(f\"      Progress: {i + 1}/{len(images)}\")\n",
        "\n",
        "    copy_images(train_images, 'train')\n",
        "    copy_images(val_images, 'valid')\n",
        "    copy_images(test_images, 'test')\n",
        "\n",
        "    shutil.rmtree('/content/temp_images', ignore_errors=True)\n",
        "\n",
        "    print(f\"\\n‚úÖ Dataset created:\")\n",
        "    print(f\"   üìÇ Train: {len(train_images)} images\")\n",
        "    print(f\"   üìÇ Valid: {len(val_images)} images\")\n",
        "    print(f\"   üìÇ Test: {len(test_images)} images\")\n"
      ],
      "metadata": {
        "id": "RGGFJs9IKcq2",
        "outputId": "69ce6fab-b988-42e5-aa13-4c612bea5ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Extracting all ZIP files...\n",
            "============================================================\n",
            "   Extracting: cow breed-1.zip (626.5 MB)\n",
            "      ‚úÖ Done\n",
            "   Extracting: cow breed-2.zip (0.2 MB)\n",
            "      ‚úÖ Done\n",
            "   Extracting: cow breed-3.zip (0.5 MB)\n",
            "      ‚úÖ Done\n",
            "\n",
            "‚úÖ Found 2201 images\n",
            "   Copying 1540 to train...\n",
            "      Progress: 500/1540\n",
            "      Progress: 1000/1540\n",
            "      Progress: 1500/1540\n",
            "   Copying 330 to valid...\n",
            "   Copying 331 to test...\n",
            "\n",
            "‚úÖ Dataset created:\n",
            "   üìÇ Train: 1540 images\n",
            "   üìÇ Valid: 330 images\n",
            "   üìÇ Test: 331 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE: PyTorch Fix + Create data.yaml + Train Model\n",
        "# Run this entire cell\n",
        "\n",
        "# Step 1: Apply PyTorch Fix\n",
        "import torch\n",
        "import functools\n",
        "\n",
        "_original_torch_load = torch.load\n",
        "\n",
        "@functools.wraps(_original_torch_load)\n",
        "def _patched_load(f, map_location=None, pickle_module=None, *, weights_only=None, mmap=None, **kwargs):\n",
        "    return _original_torch_load(f, map_location=map_location, pickle_module=pickle_module,\n",
        "                                 weights_only=False, mmap=mmap, **kwargs)\n",
        "\n",
        "torch.load = _patched_load\n",
        "print(\"‚úÖ PyTorch patch applied!\")\n",
        "\n",
        "# Step 2: Create data.yaml\n",
        "import os\n",
        "\n",
        "yaml_content = \"\"\"names:\n",
        "- cattle\n",
        "nc: 1\n",
        "path: /content/detection_dataset\n",
        "test: test/images\n",
        "train: train/images\n",
        "val: valid/images\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = '/content/detection_dataset/data.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"‚úÖ data.yaml created!\")\n",
        "\n",
        "# Step 3: Train model\n",
        "print(\"\\nüöÄ Starting YOLOv8-Nano Training...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"üìä Dataset: 1,540 train, 330 valid, 331 test\")\n",
        "print(f\"üñ•Ô∏è Device: CPU\")\n",
        "print(f\"üìê Image size: 320x320\")\n",
        "print(f\"üîÑ Epochs: 20\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "results = model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=20,\n",
        "    imgsz=320,\n",
        "    batch=16,\n",
        "    name='cattle_detector',\n",
        "    project='cattle_breed_recognition',\n",
        "    device='cpu',\n",
        "    patience=5,\n",
        "    save=True,\n",
        "    plots=True\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Training complete!\")\n"
      ],
      "metadata": {
        "id": "0l5xrnS-P4iz",
        "outputId": "ab5403e0-1cc8-4350-f5a8-70cbbf2e4462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PyTorch patch applied!\n",
            "‚úÖ data.yaml created!\n",
            "\n",
            "üöÄ Starting YOLOv8-Nano Training...\n",
            "============================================================\n",
            "üìä Dataset: 1,540 train, 330 valid, 331 test\n",
            "üñ•Ô∏è Device: CPU\n",
            "üìê Image size: 320x320\n",
            "üîÑ Epochs: 20\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 67.4MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RecursionError",
          "evalue": "maximum recursion depth exceeded",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3733214188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m results = model.train(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.pt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;34m\"\"\"Loads a single model weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ema'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;34m'ultralytics.yolo.v8'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ultralytics.models.yolo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m  \u001b[0;31m# load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3733214188.py\u001b[0m in \u001b[0;36m_patched_load\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_original_torch_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_patched_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     return _original_torch_load(f, map_location=map_location, pickle_module=pickle_module, \n\u001b[0m\u001b[1;32m     13\u001b[0m                                  weights_only=False, mmap=mmap, **kwargs)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2725925807.py\u001b[0m in \u001b[0;36m_patched_load\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_original_torch_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_patched_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     return _original_torch_load(f, map_location=map_location, pickle_module=pickle_module, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                  weights_only=False, mmap=mmap, **kwargs)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "... last 1 frames repeated, from the frame below ...\n",
            "\u001b[0;32m/tmp/ipython-input-2725925807.py\u001b[0m in \u001b[0;36m_patched_load\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_original_torch_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_patched_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     return _original_torch_load(f, map_location=map_location, pickle_module=pickle_module, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                  weights_only=False, mmap=mmap, **kwargs)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feZXxitD4Xaq"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f-JVEDo4Xar"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Install YOLOv8\n",
        "!pip install ultralytics==8.0.196 -q\n",
        "!pip install roboflow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYNrV6Qu4Xas"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive for data storage\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set paths\n",
        "BASE_PATH = '/content/drive/MyDrive/cattle_breed_recognition'\n",
        "DATA_PATH = f'{BASE_PATH}/data'\n",
        "MODELS_PATH = f'{BASE_PATH}/models'\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"Base Path: {BASE_PATH}\")\n",
        "print(f\"Data Path: {DATA_PATH}\")\n",
        "print(f\"Models Path: {MODELS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu3RHhRy4Xat"
      },
      "source": [
        "## 2. Prepare Dataset\n",
        "\n",
        "### Option A: Download from Roboflow (Recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSmUb-E24Xat"
      },
      "outputs": [],
      "source": [
        "# Option A: Download cattle detection dataset from Roboflow\n",
        "# You can find cattle detection datasets at: https://universe.roboflow.com/\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
        "project = rf.workspace(\"workspace-name\").project(\"cattle-detection\")\n",
        "dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "# The dataset will be downloaded in YOLOv8 format\n",
        "DATASET_PATH = dataset.location\n",
        "print(f\"Dataset downloaded to: {DATASET_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS985VLP4Xau"
      },
      "source": [
        "### Option B: Use Local Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ri-FoNB4Xau"
      },
      "outputs": [],
      "source": [
        "# Option B: Upload your own dataset\n",
        "# Dataset structure should be:\n",
        "# dataset/\n",
        "# ‚îú‚îÄ‚îÄ data.yaml\n",
        "# ‚îú‚îÄ‚îÄ train/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "# ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "# ‚îú‚îÄ‚îÄ valid/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "# ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "# ‚îî‚îÄ‚îÄ test/\n",
        "#     ‚îú‚îÄ‚îÄ images/\n",
        "#     ‚îî‚îÄ‚îÄ labels/\n",
        "\n",
        "# Upload dataset.zip to Colab and extract\n",
        "# !unzip dataset.zip -d {DATA_PATH}\n",
        "\n",
        "# DATASET_PATH = f'{DATA_PATH}/dataset'\n",
        "# print(f\"Dataset path: {DATASET_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5ZVUgld4Xav"
      },
      "source": [
        "### Option C: Create Dataset from Kaggle Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjXjUzno4Xav"
      },
      "outputs": [],
      "source": [
        "# Option C: Create detection dataset from Kaggle breed images\n",
        "# This creates bounding boxes around the entire image (simple approach)\n",
        "\n",
        "def create_detection_dataset_from_classification(source_dir, output_dir, class_name='cattle'):\n",
        "    \"\"\"\n",
        "    Create YOLO format detection dataset from classification images.\n",
        "    Uses entire image as bounding box.\n",
        "\n",
        "    Args:\n",
        "        source_dir: Directory with class folders (classification format)\n",
        "        output_dir: Output directory for YOLO format\n",
        "        class_name: Class name for detection (cattle/buffalo)\n",
        "    \"\"\"\n",
        "    import random\n",
        "\n",
        "    # Create output directories\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        os.makedirs(f'{output_dir}/{split}/images', exist_ok=True)\n",
        "        os.makedirs(f'{output_dir}/{split}/labels', exist_ok=True)\n",
        "\n",
        "    # Collect all images\n",
        "    all_images = []\n",
        "    for breed_folder in os.listdir(source_dir):\n",
        "        breed_path = os.path.join(source_dir, breed_folder)\n",
        "        if os.path.isdir(breed_path):\n",
        "            for img_name in os.listdir(breed_path):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    all_images.append({\n",
        "                        'path': os.path.join(breed_path, img_name),\n",
        "                        'name': f\"{breed_folder}_{img_name}\"\n",
        "                    })\n",
        "\n",
        "    print(f\"Total images found: {len(all_images)}\")\n",
        "\n",
        "    # Shuffle and split\n",
        "    random.shuffle(all_images)\n",
        "    n = len(all_images)\n",
        "    train_split = int(0.7 * n)\n",
        "    val_split = int(0.85 * n)\n",
        "\n",
        "    splits = {\n",
        "        'train': all_images[:train_split],\n",
        "        'valid': all_images[train_split:val_split],\n",
        "        'test': all_images[val_split:]\n",
        "    }\n",
        "\n",
        "    # Process each split\n",
        "    for split_name, images in splits.items():\n",
        "        print(f\"Processing {split_name}: {len(images)} images\")\n",
        "\n",
        "        for img_info in images:\n",
        "            # Copy image\n",
        "            img_path = img_info['path']\n",
        "            img_name = img_info['name']\n",
        "            dest_img = f'{output_dir}/{split_name}/images/{img_name}'\n",
        "            shutil.copy(img_path, dest_img)\n",
        "\n",
        "            # Get image dimensions\n",
        "            img = cv2.imread(img_path)\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            # Create YOLO format label (entire image as bbox)\n",
        "            # YOLO format: class x_center y_center width height (normalized 0-1)\n",
        "            # class 0 = cattle\n",
        "            label_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
        "            label_path = f'{output_dir}/{split_name}/labels/{label_name}'\n",
        "\n",
        "            # Entire image as bounding box\n",
        "            x_center = 0.5\n",
        "            y_center = 0.5\n",
        "            width = 1.0\n",
        "            height = 1.0\n",
        "\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "    print(f\"Dataset created at: {output_dir}\")\n",
        "    return output_dir\n",
        "\n",
        "# Uncomment to use:\n",
        "# SOURCE_DATA = f'{DATA_PATH}/raw/kaggle_cattle_images'\n",
        "# OUTPUT_DATA = f'{DATA_PATH}/detection_dataset'\n",
        "# create_detection_dataset_from_classification(SOURCE_DATA, OUTPUT_DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OriPyEW4Xav"
      },
      "source": [
        "## 3. Create data.yaml Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPX48jrd4Xaw"
      },
      "outputs": [],
      "source": [
        "# Create data.yaml for YOLOv8\n",
        "\n",
        "def create_data_yaml(dataset_path, output_path):\n",
        "    \"\"\"\n",
        "    Create data.yaml configuration file for YOLOv8 training.\n",
        "    \"\"\"\n",
        "    data_config = {\n",
        "        'path': dataset_path,\n",
        "        'train': 'train/images',\n",
        "        'val': 'valid/images',\n",
        "        'test': 'test/images',\n",
        "        'nc': 1,  # Number of classes (1 = cattle/buffalo)\n",
        "        'names': ['cattle']  # Class names\n",
        "    }\n",
        "\n",
        "    with open(output_path, 'w') as f:\n",
        "        yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "    print(f\"Created data.yaml at: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Create data.yaml\n",
        "DATASET_PATH = f'{DATA_PATH}/detection_dataset'  # Update this path\n",
        "YAML_PATH = create_data_yaml(DATASET_PATH, f'{DATASET_PATH}/data.yaml')\n",
        "\n",
        "# Display config\n",
        "with open(YAML_PATH, 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QH_Kv3L4Xaw"
      },
      "source": [
        "## 4. Train YOLOv8-Nano Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX8uvrsb4Xaw"
      },
      "outputs": [],
      "source": [
        "# Load YOLOv8-Nano model (pretrained on COCO)\n",
        "model = YOLO('yolov8n.pt')  # Nano model\n",
        "\n",
        "# Training parameters\n",
        "training_params = {\n",
        "    'data': YAML_PATH,\n",
        "    'epochs': 100,              # Number of training epochs\n",
        "    'imgsz': 416,               # Image size (smaller for mobile)\n",
        "    'batch': 32,                # Batch size\n",
        "    'name': 'cattle_detector',  # Experiment name\n",
        "    'project': MODELS_PATH,     # Save directory\n",
        "    'device': 0,                # GPU device\n",
        "    'patience': 20,             # Early stopping patience\n",
        "    'save': True,               # Save checkpoints\n",
        "    'save_period': 10,          # Save every N epochs\n",
        "    'workers': 4,               # Data loading workers\n",
        "    'pretrained': True,         # Use pretrained weights\n",
        "    'optimizer': 'auto',        # Optimizer (auto selects AdamW)\n",
        "    'lr0': 0.01,                # Initial learning rate\n",
        "    'lrf': 0.01,                # Final learning rate\n",
        "    'momentum': 0.937,          # SGD momentum\n",
        "    'weight_decay': 0.0005,     # Weight decay\n",
        "    'warmup_epochs': 3,         # Warmup epochs\n",
        "    'warmup_momentum': 0.8,     # Warmup momentum\n",
        "    'warmup_bias_lr': 0.1,      # Warmup bias learning rate\n",
        "    'box': 7.5,                 # Box loss gain\n",
        "    'cls': 0.5,                 # Classification loss gain\n",
        "    'dfl': 1.5,                 # Distribution focal loss gain\n",
        "    'pose': 12.0,               # Pose loss gain\n",
        "    'kobj': 1.0,                # Keypoint objectness loss gain\n",
        "    'label_smoothing': 0.0,     # Label smoothing\n",
        "    'nbs': 64,                  # Nominal batch size\n",
        "    'hsv_h': 0.015,             # HSV-Hue augmentation\n",
        "    'hsv_s': 0.7,               # HSV-Saturation augmentation\n",
        "    'hsv_v': 0.4,               # HSV-Value augmentation\n",
        "    'degrees': 15.0,            # Rotation augmentation (+/- deg)\n",
        "    'translate': 0.1,           # Translation augmentation (+/- fraction)\n",
        "    'scale': 0.5,               # Scaling augmentation (+/- gain)\n",
        "    'shear': 0.0,               # Shear augmentation (+/- deg)\n",
        "    'perspective': 0.0,         # Perspective augmentation (+/- fraction)\n",
        "    'flipud': 0.0,              # Flip up-down probability\n",
        "    'fliplr': 0.5,              # Flip left-right probability\n",
        "    'mosaic': 1.0,              # Mosaic augmentation probability\n",
        "    'mixup': 0.0,               # Mixup augmentation probability\n",
        "    'copy_paste': 0.0,          # Copy-paste augmentation probability\n",
        "    'auto_augment': 'randaugment',  # Auto augmentation policy\n",
        "    'erasing': 0.4,             # Random erasing probability\n",
        "    'crop_fraction': 1.0,       # Image crop fraction\n",
        "}\n",
        "\n",
        "print(\"Starting YOLOv8-Nano training...\")\n",
        "print(f\"Dataset: {YAML_PATH}\")\n",
        "print(f\"Image size: 416x416\")\n",
        "print(f\"Epochs: 100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIWfsg8N4Xaw"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "results = model.train(**training_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5mhIhmc4Xaw"
      },
      "source": [
        "## 5. Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9zWan0J4Xaw"
      },
      "outputs": [],
      "source": [
        "# Validate the model\n",
        "metrics = model.val()\n",
        "\n",
        "print(\"\\n=== Validation Metrics ===\")\n",
        "print(f\"mAP@50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnYHiy1N4Xax"
      },
      "outputs": [],
      "source": [
        "# Plot training results\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Display results plot\n",
        "results_path = f'{MODELS_PATH}/cattle_detector'\n",
        "if os.path.exists(f'{results_path}/results.png'):\n",
        "    display(Image(filename=f'{results_path}/results.png', width=800))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjgOhovg4Xax"
      },
      "outputs": [],
      "source": [
        "# Test on sample images\n",
        "test_images_path = f'{DATASET_PATH}/test/images'\n",
        "test_images = os.listdir(test_images_path)[:5]\n",
        "\n",
        "for img_name in test_images:\n",
        "    img_path = os.path.join(test_images_path, img_name)\n",
        "    results = model.predict(img_path, save=True, conf=0.25)\n",
        "\n",
        "    # Display result\n",
        "    result_img = f'{results[0].save_dir}/{img_name}'\n",
        "    if os.path.exists(result_img):\n",
        "        display(Image(filename=result_img, width=400))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcTJQi-X4Xax"
      },
      "source": [
        "## 6. Export to TFLite with INT8 Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du5Vf5i84Xax"
      },
      "outputs": [],
      "source": [
        "# Export to TFLite format\n",
        "# YOLOv8 supports direct TFLite export\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO(f'{MODELS_PATH}/cattle_detector/weights/best.pt')\n",
        "\n",
        "# Export to TFLite\n",
        "best_model.export(\n",
        "    format='tflite',\n",
        "    imgsz=416,\n",
        "    int8=True,           # INT8 quantization\n",
        "    data=YAML_PATH,      # Dataset for calibration\n",
        "    batch=1,\n",
        "    optimize=True,       # Optimize for mobile\n",
        "    simplify=True,       # Simplify model\n",
        "    opset=12,            # ONNX opset version\n",
        "    workspace=4,         # TensorRT workspace size (GB)\n",
        ")\n",
        "\n",
        "print(\"Model exported to TFLite with INT8 quantization!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfJ0cKs94Xax"
      },
      "outputs": [],
      "source": [
        "# Check exported model size\n",
        "import glob\n",
        "\n",
        "tflite_files = glob.glob(f'{MODELS_PATH}/cattle_detector/weights/*.tflite')\n",
        "for tflite_file in tflite_files:\n",
        "    size_mb = os.path.getsize(tflite_file) / (1024 * 1024)\n",
        "    print(f\"{os.path.basename(tflite_file)}: {size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2GQ6SZ84Xax"
      },
      "source": [
        "## 7. Test TFLite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SRt1nCA4Xay"
      },
      "outputs": [],
      "source": [
        "# Test TFLite model inference\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def test_tflite_model(tflite_path, test_image_path):\n",
        "    \"\"\"\n",
        "    Test TFLite model inference on a single image.\n",
        "    \"\"\"\n",
        "    # Load TFLite model\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input/output details\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    print(f\"Input shape: {input_details[0]['shape']}\")\n",
        "    print(f\"Input dtype: {input_details[0]['dtype']}\")\n",
        "    print(f\"Output shape: {output_details[0]['shape']}\")\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = cv2.imread(test_image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (416, 416))\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Run inference\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], img)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    inference_time = (time.time() - start_time) * 1000\n",
        "    print(f\"\\nInference time: {inference_time:.2f} ms\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "    return output\n",
        "\n",
        "# Test on sample image\n",
        "tflite_path = glob.glob(f'{MODELS_PATH}/cattle_detector/weights/*_int8.tflite')[0]\n",
        "test_image = os.path.join(test_images_path, test_images[0])\n",
        "\n",
        "print(f\"Testing TFLite model: {tflite_path}\")\n",
        "print(f\"Test image: {test_image}\")\n",
        "\n",
        "output = test_tflite_model(tflite_path, test_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UwZOO_14Xay"
      },
      "source": [
        "## 8. Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb1ZS8SX4Xay"
      },
      "outputs": [],
      "source": [
        "# Copy final models to output directory\n",
        "OUTPUT_DIR = f'{MODELS_PATH}/final'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Copy best PyTorch model\n",
        "shutil.copy(\n",
        "    f'{MODELS_PATH}/cattle_detector/weights/best.pt',\n",
        "    f'{OUTPUT_DIR}/yolov8_nano_cattle_detector.pt'\n",
        ")\n",
        "\n",
        "# Copy TFLite model\n",
        "for tflite_file in tflite_files:\n",
        "    shutil.copy(tflite_file, OUTPUT_DIR)\n",
        "\n",
        "print(f\"Final models saved to: {OUTPUT_DIR}\")\n",
        "print(\"\\nFiles:\")\n",
        "for f in os.listdir(OUTPUT_DIR):\n",
        "    size_mb = os.path.getsize(os.path.join(OUTPUT_DIR, f)) / (1024 * 1024)\n",
        "    print(f\"  {f}: {size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijm3T76E4Xay"
      },
      "source": [
        "## 9. Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXnaY9GC4Xay"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"YOLOv8-Nano Detection Model Training Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nModel: YOLOv8-Nano\")\n",
        "print(f\"Task: Cattle/Buffalo Detection\")\n",
        "print(f\"Input Size: 416x416\")\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  mAP@50: {metrics.box.map50:.4f}\")\n",
        "print(f\"  mAP@50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"  Recall: {metrics.box.mr:.4f}\")\n",
        "print(f\"\\nModel Files:\")\n",
        "print(f\"  PyTorch: yolov8_nano_cattle_detector.pt\")\n",
        "print(f\"  TFLite INT8: *_int8.tflite (~5 MB)\")\n",
        "print(f\"\\nReady for Stage 2: Breed Classification with EfficientNet-B0\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}