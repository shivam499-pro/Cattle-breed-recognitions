{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8-Nano Detection Model Training\n",
    "## Cattle Breed Recognition System - Stage 1: Animal Detection\n",
    "\n",
    "This notebook trains a YOLOv8-Nano model for detecting cattle and buffaloes in images.\n",
    "\n",
    "**Model Specifications:**\n",
    "- Model: YOLOv8-Nano (smallest, fastest)\n",
    "- Input Size: 416x416\n",
    "- Output: Bounding box (x, y, w, h) for animal detection\n",
    "- Final Size: ~5 MB (after INT8 quantization)\n",
    "- Inference: ~20ms on mobile\n",
    "\n",
    "**Author:** SIH 2025 Team\n",
    "**Problem Statement:** SIH25004 - Image-based Breed Recognition for Cattle and Buffaloes of India"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Install YOLOv8\n",
    "!pip install ultralytics==8.0.196 -q\n",
    "!pip install roboflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive for data storage\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths\n",
    "BASE_PATH = '/content/drive/MyDrive/cattle_breed_recognition'\n",
    "DATA_PATH = f'{BASE_PATH}/data'\n",
    "MODELS_PATH = f'{BASE_PATH}/models'\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Base Path: {BASE_PATH}\")\n",
    "print(f\"Data Path: {DATA_PATH}\")\n",
    "print(f\"Models Path: {MODELS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset\n",
    "\n",
    "### Option A: Download from Roboflow (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Download cattle detection dataset from Roboflow\n",
    "# You can find cattle detection datasets at: https://universe.roboflow.com/\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace(\"workspace-name\").project(\"cattle-detection\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n",
    "\n",
    "# The dataset will be downloaded in YOLOv8 format\n",
    "DATASET_PATH = dataset.location\n",
    "print(f\"Dataset downloaded to: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Use Local Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Upload your own dataset\n",
    "# Dataset structure should be:\n",
    "# dataset/\n",
    "# ├── data.yaml\n",
    "# ├── train/\n",
    "# │   ├── images/\n",
    "# │   └── labels/\n",
    "# ├── valid/\n",
    "# │   ├── images/\n",
    "# │   └── labels/\n",
    "# └── test/\n",
    "#     ├── images/\n",
    "#     └── labels/\n",
    "\n",
    "# Upload dataset.zip to Colab and extract\n",
    "# !unzip dataset.zip -d {DATA_PATH}\n",
    "\n",
    "# DATASET_PATH = f'{DATA_PATH}/dataset'\n",
    "# print(f\"Dataset path: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Create Dataset from Kaggle Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option C: Create detection dataset from Kaggle breed images\n",
    "# This creates bounding boxes around the entire image (simple approach)\n",
    "\n",
    "def create_detection_dataset_from_classification(source_dir, output_dir, class_name='cattle'):\n",
    "    \"\"\"\n",
    "    Create YOLO format detection dataset from classification images.\n",
    "    Uses entire image as bounding box.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Directory with class folders (classification format)\n",
    "        output_dir: Output directory for YOLO format\n",
    "        class_name: Class name for detection (cattle/buffalo)\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    # Create output directories\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        os.makedirs(f'{output_dir}/{split}/images', exist_ok=True)\n",
    "        os.makedirs(f'{output_dir}/{split}/labels', exist_ok=True)\n",
    "    \n",
    "    # Collect all images\n",
    "    all_images = []\n",
    "    for breed_folder in os.listdir(source_dir):\n",
    "        breed_path = os.path.join(source_dir, breed_folder)\n",
    "        if os.path.isdir(breed_path):\n",
    "            for img_name in os.listdir(breed_path):\n",
    "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    all_images.append({\n",
    "                        'path': os.path.join(breed_path, img_name),\n",
    "                        'name': f\"{breed_folder}_{img_name}\"\n",
    "                    })\n",
    "    \n",
    "    print(f\"Total images found: {len(all_images)}\")\n",
    "    \n",
    "    # Shuffle and split\n",
    "    random.shuffle(all_images)\n",
    "    n = len(all_images)\n",
    "    train_split = int(0.7 * n)\n",
    "    val_split = int(0.85 * n)\n",
    "    \n",
    "    splits = {\n",
    "        'train': all_images[:train_split],\n",
    "        'valid': all_images[train_split:val_split],\n",
    "        'test': all_images[val_split:]\n",
    "    }\n",
    "    \n",
    "    # Process each split\n",
    "    for split_name, images in splits.items():\n",
    "        print(f\"Processing {split_name}: {len(images)} images\")\n",
    "        \n",
    "        for img_info in images:\n",
    "            # Copy image\n",
    "            img_path = img_info['path']\n",
    "            img_name = img_info['name']\n",
    "            dest_img = f'{output_dir}/{split_name}/images/{img_name}'\n",
    "            shutil.copy(img_path, dest_img)\n",
    "            \n",
    "            # Get image dimensions\n",
    "            img = cv2.imread(img_path)\n",
    "            h, w = img.shape[:2]\n",
    "            \n",
    "            # Create YOLO format label (entire image as bbox)\n",
    "            # YOLO format: class x_center y_center width height (normalized 0-1)\n",
    "            # class 0 = cattle\n",
    "            label_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
    "            label_path = f'{output_dir}/{split_name}/labels/{label_name}'\n",
    "            \n",
    "            # Entire image as bounding box\n",
    "            x_center = 0.5\n",
    "            y_center = 0.5\n",
    "            width = 1.0\n",
    "            height = 1.0\n",
    "            \n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
    "    \n",
    "    print(f\"Dataset created at: {output_dir}\")\n",
    "    return output_dir\n",
    "\n",
    "# Uncomment to use:\n",
    "# SOURCE_DATA = f'{DATA_PATH}/raw/kaggle_cattle_images'\n",
    "# OUTPUT_DATA = f'{DATA_PATH}/detection_dataset'\n",
    "# create_detection_dataset_from_classification(SOURCE_DATA, OUTPUT_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create data.yaml Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml for YOLOv8\n",
    "\n",
    "def create_data_yaml(dataset_path, output_path):\n",
    "    \"\"\"\n",
    "    Create data.yaml configuration file for YOLOv8 training.\n",
    "    \"\"\"\n",
    "    data_config = {\n",
    "        'path': dataset_path,\n",
    "        'train': 'train/images',\n",
    "        'val': 'valid/images',\n",
    "        'test': 'test/images',\n",
    "        'nc': 1,  # Number of classes (1 = cattle/buffalo)\n",
    "        'names': ['cattle']  # Class names\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Created data.yaml at: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Create data.yaml\n",
    "DATASET_PATH = f'{DATA_PATH}/detection_dataset'  # Update this path\n",
    "YAML_PATH = create_data_yaml(DATASET_PATH, f'{DATASET_PATH}/data.yaml')\n",
    "\n",
    "# Display config\n",
    "with open(YAML_PATH, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train YOLOv8-Nano Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8-Nano model (pretrained on COCO)\n",
    "model = YOLO('yolov8n.pt')  # Nano model\n",
    "\n",
    "# Training parameters\n",
    "training_params = {\n",
    "    'data': YAML_PATH,\n",
    "    'epochs': 100,              # Number of training epochs\n",
    "    'imgsz': 416,               # Image size (smaller for mobile)\n",
    "    'batch': 32,                # Batch size\n",
    "    'name': 'cattle_detector',  # Experiment name\n",
    "    'project': MODELS_PATH,     # Save directory\n",
    "    'device': 0,                # GPU device\n",
    "    'patience': 20,             # Early stopping patience\n",
    "    'save': True,               # Save checkpoints\n",
    "    'save_period': 10,          # Save every N epochs\n",
    "    'workers': 4,               # Data loading workers\n",
    "    'pretrained': True,         # Use pretrained weights\n",
    "    'optimizer': 'auto',        # Optimizer (auto selects AdamW)\n",
    "    'lr0': 0.01,                # Initial learning rate\n",
    "    'lrf': 0.01,                # Final learning rate\n",
    "    'momentum': 0.937,          # SGD momentum\n",
    "    'weight_decay': 0.0005,     # Weight decay\n",
    "    'warmup_epochs': 3,         # Warmup epochs\n",
    "    'warmup_momentum': 0.8,     # Warmup momentum\n",
    "    'warmup_bias_lr': 0.1,      # Warmup bias learning rate\n",
    "    'box': 7.5,                 # Box loss gain\n",
    "    'cls': 0.5,                 # Classification loss gain\n",
    "    'dfl': 1.5,                 # Distribution focal loss gain\n",
    "    'pose': 12.0,               # Pose loss gain\n",
    "    'kobj': 1.0,                # Keypoint objectness loss gain\n",
    "    'label_smoothing': 0.0,     # Label smoothing\n",
    "    'nbs': 64,                  # Nominal batch size\n",
    "    'hsv_h': 0.015,             # HSV-Hue augmentation\n",
    "    'hsv_s': 0.7,               # HSV-Saturation augmentation\n",
    "    'hsv_v': 0.4,               # HSV-Value augmentation\n",
    "    'degrees': 15.0,            # Rotation augmentation (+/- deg)\n",
    "    'translate': 0.1,           # Translation augmentation (+/- fraction)\n",
    "    'scale': 0.5,               # Scaling augmentation (+/- gain)\n",
    "    'shear': 0.0,               # Shear augmentation (+/- deg)\n",
    "    'perspective': 0.0,         # Perspective augmentation (+/- fraction)\n",
    "    'flipud': 0.0,              # Flip up-down probability\n",
    "    'fliplr': 0.5,              # Flip left-right probability\n",
    "    'mosaic': 1.0,              # Mosaic augmentation probability\n",
    "    'mixup': 0.0,               # Mixup augmentation probability\n",
    "    'copy_paste': 0.0,          # Copy-paste augmentation probability\n",
    "    'auto_augment': 'randaugment',  # Auto augmentation policy\n",
    "    'erasing': 0.4,             # Random erasing probability\n",
    "    'crop_fraction': 1.0,       # Image crop fraction\n",
    "}\n",
    "\n",
    "print(\"Starting YOLOv8-Nano training...\")\n",
    "print(f\"Dataset: {YAML_PATH}\")\n",
    "print(f\"Image size: 416x416\")\n",
    "print(f\"Epochs: 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "results = model.train(**training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\n=== Validation Metrics ===\")\n",
    "print(f\"mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Display results plot\n",
    "results_path = f'{MODELS_PATH}/cattle_detector'\n",
    "if os.path.exists(f'{results_path}/results.png'):\n",
    "    display(Image(filename=f'{results_path}/results.png', width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample images\n",
    "test_images_path = f'{DATASET_PATH}/test/images'\n",
    "test_images = os.listdir(test_images_path)[:5]\n",
    "\n",
    "for img_name in test_images:\n",
    "    img_path = os.path.join(test_images_path, img_name)\n",
    "    results = model.predict(img_path, save=True, conf=0.25)\n",
    "    \n",
    "    # Display result\n",
    "    result_img = f'{results[0].save_dir}/{img_name}'\n",
    "    if os.path.exists(result_img):\n",
    "        display(Image(filename=result_img, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export to TFLite with INT8 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TFLite format\n",
    "# YOLOv8 supports direct TFLite export\n",
    "\n",
    "# Load best model\n",
    "best_model = YOLO(f'{MODELS_PATH}/cattle_detector/weights/best.pt')\n",
    "\n",
    "# Export to TFLite\n",
    "best_model.export(\n",
    "    format='tflite',\n",
    "    imgsz=416,\n",
    "    int8=True,           # INT8 quantization\n",
    "    data=YAML_PATH,      # Dataset for calibration\n",
    "    batch=1,\n",
    "    optimize=True,       # Optimize for mobile\n",
    "    simplify=True,       # Simplify model\n",
    "    opset=12,            # ONNX opset version\n",
    "    workspace=4,         # TensorRT workspace size (GB)\n",
    ")\n",
    "\n",
    "print(\"Model exported to TFLite with INT8 quantization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check exported model size\n",
    "import glob\n",
    "\n",
    "tflite_files = glob.glob(f'{MODELS_PATH}/cattle_detector/weights/*.tflite')\n",
    "for tflite_file in tflite_files:\n",
    "    size_mb = os.path.getsize(tflite_file) / (1024 * 1024)\n",
    "    print(f\"{os.path.basename(tflite_file)}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TFLite model inference\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def test_tflite_model(tflite_path, test_image_path):\n",
    "    \"\"\"\n",
    "    Test TFLite model inference on a single image.\n",
    "    \"\"\"\n",
    "    # Load TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input/output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(f\"Input shape: {input_details[0]['shape']}\")\n",
    "    print(f\"Input dtype: {input_details[0]['dtype']}\")\n",
    "    print(f\"Output shape: {output_details[0]['shape']}\")\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(test_image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (416, 416))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Run inference\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], img)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    inference_time = (time.time() - start_time) * 1000\n",
    "    print(f\"\\nInference time: {inference_time:.2f} ms\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test on sample image\n",
    "tflite_path = glob.glob(f'{MODELS_PATH}/cattle_detector/weights/*_int8.tflite')[0]\n",
    "test_image = os.path.join(test_images_path, test_images[0])\n",
    "\n",
    "print(f\"Testing TFLite model: {tflite_path}\")\n",
    "print(f\"Test image: {test_image}\")\n",
    "\n",
    "output = test_tflite_model(tflite_path, test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy final models to output directory\n",
    "OUTPUT_DIR = f'{MODELS_PATH}/final'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Copy best PyTorch model\n",
    "shutil.copy(\n",
    "    f'{MODELS_PATH}/cattle_detector/weights/best.pt',\n",
    "    f'{OUTPUT_DIR}/yolov8_nano_cattle_detector.pt'\n",
    ")\n",
    "\n",
    "# Copy TFLite model\n",
    "for tflite_file in tflite_files:\n",
    "    shutil.copy(tflite_file, OUTPUT_DIR)\n",
    "\n",
    "print(f\"Final models saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nFiles:\")\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    size_mb = os.path.getsize(os.path.join(OUTPUT_DIR, f)) / (1024 * 1024)\n",
    "    print(f\"  {f}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"YOLOv8-Nano Detection Model Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: YOLOv8-Nano\")\n",
    "print(f\"Task: Cattle/Buffalo Detection\")\n",
    "print(f\"Input Size: 416x416\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall: {metrics.box.mr:.4f}\")\n",
    "print(f\"\\nModel Files:\")\n",
    "print(f\"  PyTorch: yolov8_nano_cattle_detector.pt\")\n",
    "print(f\"  TFLite INT8: *_int8.tflite (~5 MB)\")\n",
    "print(f\"\\nReady for Stage 2: Breed Classification with EfficientNet-B0\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
